{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torchinfo\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    model_path = \"/workspace/storage/LLaMa_Download/Converted_to_HF/llama-2-7b-chat/\"\n",
    "    lm_hidden_dim = 4096\n",
    "    device = 6\n",
    "    \n",
    "    data_folder = \"/workspace/storage/Mohammad/Early-Exit/data/true-false/publicDataset/\"\n",
    "    train_topics = ['animals', 'companies', 'elements', 'facts', 'inventions']\n",
    "    test_topics = ['cities']\n",
    "    num_shots = 2\n",
    "\n",
    "    stop_words = [\"\\nA:\"]\n",
    "\n",
    "    batch_size = 16\n",
    "    train_batch_shuffle = True\n",
    "\n",
    "    mlp_hidden_layers = [256, 128, 64]\n",
    "    mlp_output_dim = 1\n",
    "    lm_tap_layers = [16, 20, 24]\n",
    "    \n",
    "    epochs = 5\n",
    "    lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The giant anteater uses walking for locomotion.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The eagle has a habitat of urban/wild.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tortoise has an iridescent tail with eye-l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human uses for hyena include conservation, res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The platypus uses swimming for locomotion.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  label\n",
       "0    The giant anteater uses walking for locomotion.      1\n",
       "1             The eagle has a habitat of urban/wild.      0\n",
       "2  The tortoise has an iridescent tail with eye-l...      0\n",
       "3  Human uses for hyena include conservation, res...      0\n",
       "4         The platypus uses swimming for locomotion.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(Config.data_folder, \"animals_true_false.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueFalseDataset(tdu.Dataset):\n",
    "    def __init__(self, root_dir: str, topics: list[str], num_shots: int = 2):\n",
    "        self.root_dir = root_dir\n",
    "        self.topics = topics\n",
    "        data = []\n",
    "        for topic in topics:\n",
    "            df = pd.read_csv(os.path.join(root_dir, f\"{topic}_true_false.csv\"))\n",
    "            df['topic'] = topic\n",
    "            data.append(df)\n",
    "        self.data = pd.concat(data).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_demo_text(shots=2):\n",
    "        assert shots <= 6, \"Number of shots should be less than or equal to 6.\"\n",
    "\n",
    "        question, answer = [], []\n",
    "        \n",
    "        question.append(\"Human life expectancy in the United States is 78 years.\")\n",
    "        answer.append(\"true\")\n",
    "\n",
    "        question.append(\"Dwight D. Eisenhower was president of the United States in 2020.\")\n",
    "        answer.append(\"false\")\n",
    "\n",
    "        question.append(\"Dwight D. Eisenhower belonged to the Republican Party.\")\n",
    "        answer.append(\"true\")\n",
    "\n",
    "        question.append(\"The 1992 Olympics were held in Paris, France.\")\n",
    "        answer.append(\"false\")\n",
    "\n",
    "        question.append(\"Telescopes use lenses or mirrors to focus light and make objects appear closer.\")\n",
    "        answer.append(\"true\")\n",
    "\n",
    "        question.append(\"The United States lawmaking body is known as the White House.\")\n",
    "        answer.append(\"false\")\n",
    "\n",
    "        # Concatenate demonstration examples ...\n",
    "        demo_text = 'Interpret each statement literally, and as a sentence about the real world; carefully research each answer, without falling prey to any common myths; and reply with one word, \"true\" or \"false\".' + '\\n\\n'\n",
    "        for i in range(shots):\n",
    "            demo_text += \"S: \" + question[i] + \"\\nA: \" + answer[i] + \"\\n\\n\"\n",
    "        return demo_text\n",
    "    \n",
    "\n",
    "    def _build_prompt(self, input_text, num_shots=2):\n",
    "        demo = self._create_demo_text(num_shots)\n",
    "        input_text_prompt = demo + \"S: \" + input_text + \"\\n\" + \"A:\"\n",
    "        return input_text_prompt\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if isinstance(idx, int):\n",
    "            idx = [idx]\n",
    "        \n",
    "        rows = self.data.iloc[idx].copy()\n",
    "        rows['text'] = rows.apply(lambda z: self._build_prompt(z['statement']), axis=1)\n",
    "        return rows.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrueFalseDataset(Config.data_folder, Config.train_topics)\n",
    "test_dataset = TrueFalseDataset(Config.data_folder, Config.test_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tdu.DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=Config.train_batch_shuffle)\n",
    "test_loader = tdu.DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "\n",
    "        layer_dims = [input_dim] + hidden_dims + [output_dim]\n",
    "        layers = [nn.Linear(layer_dims[i], layer_dims[i+1]) for i in range(len(layer_dims)-1)]\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.classifier = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        \n",
    "        x = self.layers[-1](x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c58bdb4105c46c4bba08af58b904b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "lm_model = transformers.AutoModelForCausalLM.from_pretrained(Config.model_path, device_map=Config.device).eval()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(Config.model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokens = {\n",
    "    1: tokenizer.encode(\"true\", add_special_tokens=False)[0],\n",
    "    0: tokenizer.encode(\"false\", add_special_tokens=False)[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['true', 'false', 'false', 'false', 'true']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = tokenizer(train_dataset[:5]['text'], return_tensors='pt', padding=True, truncation=True, max_length=1024).to(lm_model.device)\n",
    "    outputs = lm_model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "    responses = tokenizer.batch_decode(F.softmax(outputs.logits[..., -1, :], dim=-1).argmax(dim=-1))\n",
    "    print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement': ['The giant anteater uses walking for locomotion.',\n",
       "  'The eagle has a habitat of urban/wild.',\n",
       "  'The tortoise has an iridescent tail with eye-like patterns used in courtship displays.',\n",
       "  'Human uses for hyena include conservation, research.',\n",
       "  'The platypus uses swimming for locomotion.'],\n",
       " 'label': [1, 0, 0, 0, 1],\n",
       " 'topic': ['animals', 'animals', 'animals', 'animals', 'animals'],\n",
       " 'text': ['Interpret each statement literally, and as a sentence about the real world; carefully research each answer, without falling prey to any common myths; and reply with one word, \"true\" or \"false\".\\n\\nS: Human life expectancy in the United States is 78 years.\\nA: true\\n\\nS: Dwight D. Eisenhower was president of the United States in 2020.\\nA: false\\n\\nS: The giant anteater uses walking for locomotion.\\nA:',\n",
       "  'Interpret each statement literally, and as a sentence about the real world; carefully research each answer, without falling prey to any common myths; and reply with one word, \"true\" or \"false\".\\n\\nS: Human life expectancy in the United States is 78 years.\\nA: true\\n\\nS: Dwight D. Eisenhower was president of the United States in 2020.\\nA: false\\n\\nS: The eagle has a habitat of urban/wild.\\nA:',\n",
       "  'Interpret each statement literally, and as a sentence about the real world; carefully research each answer, without falling prey to any common myths; and reply with one word, \"true\" or \"false\".\\n\\nS: Human life expectancy in the United States is 78 years.\\nA: true\\n\\nS: Dwight D. Eisenhower was president of the United States in 2020.\\nA: false\\n\\nS: The tortoise has an iridescent tail with eye-like patterns used in courtship displays.\\nA:',\n",
       "  'Interpret each statement literally, and as a sentence about the real world; carefully research each answer, without falling prey to any common myths; and reply with one word, \"true\" or \"false\".\\n\\nS: Human life expectancy in the United States is 78 years.\\nA: true\\n\\nS: Dwight D. Eisenhower was president of the United States in 2020.\\nA: false\\n\\nS: Human uses for hyena include conservation, research.\\nA:',\n",
       "  'Interpret each statement literally, and as a sentence about the real world; carefully research each answer, without falling prey to any common myths; and reply with one word, \"true\" or \"false\".\\n\\nS: Human life expectancy in the United States is 78 years.\\nA: true\\n\\nS: Dwight D. Eisenhower was president of the United States in 2020.\\nA: false\\n\\nS: The platypus uses swimming for locomotion.\\nA:']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_models = {\n",
    "    l: MLPClassifier(Config.lm_hidden_dim, Config.mlp_hidden_layers, Config.mlp_output_dim).to(Config.device)\n",
    "    for l in Config.lm_tap_layers\n",
    "}\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizers = {\n",
    "    l: torch.optim.Adam(m.parameters(), lr=Config.lr)\n",
    "    for l, m in mlp_models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, labels, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    mlp_outputs = model(x).squeeze()\n",
    "    loss = criterion(mlp_outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), mlp_outputs.detach().cpu().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### Epoch 1 #########################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99c4826b28d4798b4ea739a0ba28dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: Token Accuracy: 0.79, Probability Accuracy: 0.79\n",
      "MLPs:\n",
      "    Tap Layer 16: Train Accuracy: 0.82, Loss: 0.3951\n",
      "    Tap Layer 20: Train Accuracy: 0.82, Loss: 0.4020\n",
      "    Tap Layer 24: Train Accuracy: 0.81, Loss: 0.4060\n",
      "    Majority Voting: 0.82\n",
      "######################### Epoch 2 #########################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f53a2ac496422aad453d7b8fab4d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: Token Accuracy: 0.79, Probability Accuracy: 0.79\n",
      "MLPs:\n",
      "    Tap Layer 16: Train Accuracy: 0.84, Loss: 0.3515\n",
      "    Tap Layer 20: Train Accuracy: 0.83, Loss: 0.3558\n",
      "    Tap Layer 24: Train Accuracy: 0.83, Loss: 0.3621\n",
      "    Majority Voting: 0.84\n",
      "######################### Epoch 3 #########################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a387b8f76b47ac8ccbe7045bf49b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: Token Accuracy: 0.79, Probability Accuracy: 0.79\n",
      "MLPs:\n",
      "    Tap Layer 16: Train Accuracy: 0.85, Loss: 0.3376\n",
      "    Tap Layer 20: Train Accuracy: 0.84, Loss: 0.3417\n",
      "    Tap Layer 24: Train Accuracy: 0.84, Loss: 0.3466\n",
      "    Majority Voting: 0.85\n",
      "######################### Epoch 4 #########################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775404bae4634e34bc23a8a588ccc6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: Token Accuracy: 0.79, Probability Accuracy: 0.79\n",
      "MLPs:\n",
      "    Tap Layer 16: Train Accuracy: 0.85, Loss: 0.3334\n",
      "    Tap Layer 20: Train Accuracy: 0.84, Loss: 0.3346\n",
      "    Tap Layer 24: Train Accuracy: 0.84, Loss: 0.3403\n",
      "    Majority Voting: 0.84\n",
      "######################### Epoch 5 #########################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c895a8ffea847f0858ef2d465e2d234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: Token Accuracy: 0.79, Probability Accuracy: 0.79\n",
      "MLPs:\n",
      "    Tap Layer 16: Train Accuracy: 0.85, Loss: 0.3212\n",
      "    Tap Layer 20: Train Accuracy: 0.85, Loss: 0.3242\n",
      "    Tap Layer 24: Train Accuracy: 0.84, Loss: 0.3313\n",
      "    Majority Voting: 0.85\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(Config.epochs):\n",
    "# for epoch in range(1):\n",
    "    print(f\"{'#'*25} Epoch {epoch+1} {'#'*25}\")\n",
    "    running_loss = {l: 0.0 for l in Config.lm_tap_layers}\n",
    "    lm_predictions_token = []\n",
    "    lm_predictions_prob = []\n",
    "    mlp_predictions = {l: [] for l in Config.lm_tap_layers}\n",
    "    all_labels = []\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        inputs = tokenizer(batch[input_column][0], padding=True, return_tensors='pt', max_length=1024, truncation=True).to(Config.device)\n",
    "        with torch.no_grad():\n",
    "            lm_outputs = lm_model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "            lm_probs = F.softmax(lm_outputs.logits[..., -1, :], dim=-1)\n",
    "            lm_predictions_prob.extend(lm_probs[:, [label_tokens[0], label_tokens[1]]].tolist())\n",
    "            lm_predictions_token.extend(lm_probs.argmax(dim=-1).tolist())\n",
    "            \n",
    "            # hidden_states will be in shape (batch_size, num_layers, hidden_dim)\n",
    "            hidden_states = torch.stack(lm_outputs.hidden_states)[..., -1, :].transpose(0, 1)\n",
    "\n",
    "        labels = batch['label'][0].float().to(Config.device)\n",
    "        all_labels.extend(batch['label'][0])\n",
    "        \n",
    "        for tap_layer, mlp_model in mlp_models.items():\n",
    "            loss, mlp_pred = train_step(\n",
    "                hidden_states[..., tap_layer, :],\n",
    "                labels,\n",
    "                mlp_model,\n",
    "                criterion,\n",
    "                optimizers[tap_layer]\n",
    "            )\n",
    "            mlp_predictions[tap_layer].extend(mlp_pred.tolist())\n",
    "            running_loss[tap_layer] += loss\n",
    "        \n",
    "        # print(f\"\\t batch {i+1} loss: {loss.item()}\")\n",
    "        # if i==5: break\n",
    "    \n",
    "    all_labels = torch.tensor(all_labels)\n",
    "\n",
    "    llm_token_acc = (torch.tensor(lm_predictions_token) == torch.where(all_labels == 1, label_tokens[1], label_tokens[0]).cpu()).sum()\n",
    "    llm_token_acc = llm_token_acc / len(lm_predictions_token)\n",
    "\n",
    "    llm_prob_acc = (torch.tensor(lm_predictions_prob).argmax(dim=-1) == all_labels.cpu()).sum()\n",
    "    llm_prob_acc = llm_prob_acc / len(lm_predictions_prob)\n",
    "\n",
    "    MLP_acc = {\n",
    "        l: (torch.tensor(mlp_predictions[l]) == all_labels.cpu()).sum() / len(mlp_predictions[l])\n",
    "        for l in Config.lm_tap_layers\n",
    "    }\n",
    "\n",
    "    votes = pd.DataFrame(mlp_predictions)\n",
    "    votes['final'] = votes.mean(axis='columns').round().astype(int)\n",
    "    majority_acc = (votes['final'] == all_labels.numpy()).sum() / len(votes)\n",
    "\n",
    "    print(f\"LLM: Token Accuracy: {llm_token_acc:.2f}, Probability Accuracy: {llm_prob_acc:.2f}\")\n",
    "    print(f\"MLPs:\")\n",
    "    for l in mlp_models.keys():\n",
    "        print(f\"    Tap Layer {l}: Train Accuracy: {MLP_acc[l]:.2f}, Loss: {running_loss[l]/len(train_loader):.4f}\")\n",
    "    print(f\"    Majority Voting: {majority_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd343bd5a0d4b739dc5adf4c314a60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: Token Accuracy: 0.92, Probability Accuracy: 0.92\n",
      "MLPs:\n",
      "    Tap Layer 16: Test Accuracy: 0.93, Loss: 0.0726\n",
      "    Tap Layer 20: Test Accuracy: 0.93, Loss: 0.0715\n",
      "    Tap Layer 24: Test Accuracy: 0.92, Loss: 0.0716\n",
      "    Majority Voting: 0.93\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():    \n",
    "    running_loss = {l: 0.0 for l in Config.lm_tap_layers}\n",
    "    lm_predictions_token = []\n",
    "    lm_predictions_prob = []\n",
    "    mlp_predictions = {l: [] for l in Config.lm_tap_layers}\n",
    "    all_labels = []\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        inputs = tokenizer(batch[input_column][0], padding=True, return_tensors='pt', max_length=1024, truncation=True).to(Config.device)\n",
    "        with torch.no_grad():\n",
    "            lm_outputs = lm_model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "            lm_probs = F.softmax(lm_outputs.logits[..., -1, :], dim=-1)\n",
    "            lm_predictions_prob.extend(lm_probs[:, [label_tokens[0], label_tokens[1]]].tolist())\n",
    "            lm_predictions_token.extend(lm_probs.argmax(dim=-1).tolist())\n",
    "            \n",
    "            # hidden_states will be in shape (batch_size, num_layers, hidden_dim)\n",
    "            hidden_states = torch.stack(lm_outputs.hidden_states)[..., -1, :].transpose(0, 1)\n",
    "\n",
    "        labels = batch['label'][0].float().to(Config.device)\n",
    "        all_labels.extend(batch['label'][0])\n",
    "        \n",
    "        for tap_layer, mlp_model in mlp_models.items():\n",
    "            mlp_model.eval()\n",
    "            mlp_outputs = mlp_model(hidden_states[..., tap_layer, :]).squeeze()\n",
    "            loss = criterion(mlp_outputs, labels).item()\n",
    "            mlp_predictions[tap_layer].extend(mlp_outputs.cpu().round().tolist())\n",
    "            running_loss[tap_layer] += loss\n",
    "        \n",
    "        # print(f\"\\t batch {i+1} loss: {loss.item()}\")\n",
    "        # if i==5: break\n",
    "    \n",
    "    all_labels = torch.tensor(all_labels)\n",
    "\n",
    "    llm_token_acc = (torch.tensor(lm_predictions_token) == torch.where(all_labels == 1, label_tokens[1], label_tokens[0]).cpu()).sum()\n",
    "    llm_token_acc = llm_token_acc / len(lm_predictions_token)\n",
    "\n",
    "    llm_prob_acc = (torch.tensor(lm_predictions_prob).argmax(dim=-1) == all_labels.cpu()).sum()\n",
    "    llm_prob_acc = llm_prob_acc / len(lm_predictions_prob)\n",
    "\n",
    "    MLP_acc = {\n",
    "        l: (torch.tensor(mlp_predictions[l]) == all_labels.cpu()).sum() / len(mlp_predictions[l])\n",
    "        for l in Config.lm_tap_layers\n",
    "    }\n",
    "\n",
    "    votes = pd.DataFrame(mlp_predictions)\n",
    "    votes['final'] = votes.mean(axis='columns').round().astype(int)\n",
    "    majority_acc = (votes['final'] == all_labels.numpy()).sum() / len(votes)\n",
    "\n",
    "\n",
    "    print(f\"LLM: Token Accuracy: {llm_token_acc:.2f}, Probability Accuracy: {llm_prob_acc:.2f}\")\n",
    "    print(f\"MLPs:\")\n",
    "    for l in mlp_models.keys():\n",
    "        print(f\"    Tap Layer {l}: Test Accuracy: {MLP_acc[l]:.2f}, Loss: {running_loss[l]/len(train_loader):.4f}\")\n",
    "    print(f\"    Majority Voting: {majority_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1458 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       16   20   24  final  label\n",
       "0     0.0  1.0  0.0      0      0\n",
       "1     0.0  1.0  1.0      1      1\n",
       "2     0.0  1.0  1.0      1      1\n",
       "3     0.0  1.0  1.0      1      0\n",
       "4     0.0  1.0  1.0      1      1\n",
       "...   ...  ...  ...    ...    ...\n",
       "1453  0.0  0.0  0.0      0      0\n",
       "1454  0.0  1.0  1.0      1      0\n",
       "1455  0.0  1.0  1.0      1      1\n",
       "1456  0.0  1.0  0.0      0      0\n",
       "1457  0.0  1.0  1.0      1      1\n",
       "\n",
       "[1458 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = pd.DataFrame(mlp_predictions)\n",
    "votes['final'] = votes.mean(axis='columns').round().astype(int)\n",
    "votes['label'] = all_labels\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8820301783264746"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(votes['final'] == all_labels.numpy()).sum() / len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model for Tap Layer 16 saved.\n",
      "MLP Model for Tap Layer 20 saved.\n",
      "MLP Model for Tap Layer 24 saved.\n"
     ]
    }
   ],
   "source": [
    "save_path = \"saved_models/prompted_statement_ensemble/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for l, m in mlp_models.items():\n",
    "    torch.save(m.state_dict(), f\"{save_path}/mlp_model_tap_{l}.pt\")\n",
    "    print(f\"MLP Model for Tap Layer {l} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
